using System.Text;
using System.Text.RegularExpressions;
using System.Net.Http;
using Newtonsoft.Json;
using Newtonsoft.Json.Linq;
using GraTechCommander.Models;
using GraTechCommander.Core;

namespace GraTechCommander.Services;

public class AzureAIService
{
    private readonly HttpClient _httpClient;
    private readonly AppSettings _settings;
    private readonly FitrahEthicsEngine _ethicsEngine;

    public static readonly List<AIModel> AvailableModels = new()
    {
        // Azure Models (Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©)
        new AIModel { Id = "gpt-4.1", Name = "GPT-4.1", Description = "Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„Ø¨Ø±Ù…Ø¬Ø©", Icon = "ğŸ’»", BestFor = "Code", Provider = "Azure" },
        new AIModel { Id = "claude-opus-4-5", Name = "Claude Opus", Description = "Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„Ø¹Ø±Ø¨ÙŠ", Icon = "ğŸ¨", BestFor = "Arabic", Provider = "Azure" },
        new AIModel { Id = "DeepSeek-R1-0528", Name = "DeepSeek R1", Description = "Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„ØªØ­Ù„ÙŠÙ„", Icon = "ğŸ”¬", BestFor = "Analysis", Provider = "Azure" },
        
        // Llama Local (Ù„Ù„Ø®ØµÙˆØµÙŠØ©)
        new AIModel { Id = "llama-405b", Name = "Llama 405B", Description = "Ù…Ø­Ù„ÙŠ 100% - Ø®ØµÙˆØµÙŠØ© ÙƒØ§Ù…Ù„Ø©", Icon = "ğŸ¦™", BestFor = "Privacy", Provider = "Llama" }
    };

    public AzureAIService(AppSettings settings)
    {
        _settings = settings;
        _ethicsEngine = new FitrahEthicsEngine();
        _httpClient = new HttpClient { Timeout = TimeSpan.FromMinutes(3) };
        
        // Load API Key from Environment Variable (Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ù…Ø§Ù†)
        var apiKey = Environment.GetEnvironmentVariable("AZURE_AI_KEY") ?? _settings.AzureApiKey;
        if (!string.IsNullOrEmpty(apiKey))
            _httpClient.DefaultRequestHeaders.Add("api-key", apiKey);
    }

    public string SmartSelectModel(string text)
    {
        // Ø¥Ø°Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ¨ÙŠ Ø®ØµÙˆØµÙŠØ©
        if (_settings.UseLlamaLocal)
            return "llama-405b";
            
        bool hasArabic = Regex.IsMatch(text, @"[\u0600-\u06FF]");
        bool hasCode = Regex.IsMatch(text, @"```|function|class\s|def\s|const\s|import\s|async\s|await\s");
        bool isAnalysis = Regex.IsMatch(text.ToLower(), @"Ø­Ù„Ù„|Ù‚Ø§Ø±Ù†|Ø§Ø´Ø±Ø­|Ù„Ù…Ø§Ø°Ø§|ÙƒÙŠÙ|analyze|explain|why|how");
        bool wantsPrivacy = Regex.IsMatch(text.ToLower(), @"Ø®Ø§Øµ|Ø³Ø±ÙŠ|Ù…Ø­Ù„ÙŠ|private|local|secret");

        // Ø§Ù„Ø®ØµÙˆØµÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
        if (wantsPrivacy) return "llama-405b";
        
        // Ø«Ù… Ø­Ø³Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        if (isAnalysis) return "DeepSeek-R1-0528";
        if (hasCode) return "gpt-4.1";
        if (hasArabic) return "claude-opus-4-5";
        
        return "gpt-4.1";
    }

    public async Task<string> ChatAsync(List<ChatMessage> messages, string? modelOverride = null, CancellationToken ct = default)
    {
        var lastMessage = messages.LastOrDefault()?.Content ?? "";
        
        // ğŸŒ± ÙØ­Øµ Ø£Ø®Ù„Ø§Ù‚ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
        var ethicsAnalysis = _ethicsEngine.AnalyzeContent(lastMessage);
        
        // Ø¥Ø°Ø§ Ù…Ø­ØªÙˆÙ‰ Ø¶Ø§Ø± - Ø§Ø±ÙØ¶ Ù…Ø¨Ø§Ø´Ø±Ø©
        if (ethicsAnalysis.Classification == FitrahEthicsEngine.ContentClassification.Harmful)
        {
            return _ethicsEngine.GenerateEthicalResponse(ethicsAnalysis);
        }
        
        // Ø¥Ø°Ø§ ÙŠØ­ØªØ§Ø¬ Ù…ÙˆØ§ÙÙ‚Ø© - Ø§Ø·Ù„Ø¨Ù‡Ø§
        if (ethicsAnalysis.Classification == FitrahEthicsEngine.ContentClassification.RequiresConsent)
        {
            return _ethicsEngine.GenerateEthicalResponse(ethicsAnalysis);
        }

        string model = modelOverride ?? SmartSelectModel(lastMessage);
        var selectedModel = AvailableModels.FirstOrDefault(m => m.Id == model);
        
        string response;
        if (selectedModel?.Provider == "Llama")
            response = await ChatWithLlamaAsync(messages, ct);
        else
            response = await ChatWithAzureAsync(messages, model, ct);

        // ğŸŒ± ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ù‡Ù„ÙˆØ³Ø©
        response = _ethicsEngine.ApplyAntiHallucination(response, lastMessage);

        // Ø¥Ø¶Ø§ÙØ© ØªØ­Ø°ÙŠØ± Ø¥Ø°Ø§ Ù„Ø²Ù…
        if (ethicsAnalysis.Classification == FitrahEthicsEngine.ContentClassification.NeedsWarning)
        {
            var warning = _ethicsEngine.GenerateEthicalResponse(ethicsAnalysis);
            if (!string.IsNullOrEmpty(warning))
                response = warning + "\n\n" + response;
        }

        return response;
    }

    private async Task<string> ChatWithAzureAsync(List<ChatMessage> messages, string model, CancellationToken ct)
    {
        // Endpoints Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„Ù€ fallback
        string[] endpoints = new[]
        {
            $"{_settings.AzureEndpoint}/openai/deployments/{model}/chat/completions?api-version=2024-08-01-preview",
            $"{_settings.AzureEndpoint}/models/chat/completions?api-version=2024-05-01-preview",
        };

        var requestMessages = new List<object> { new { role = "system", content = _settings.SystemPrompt } };
        foreach (var msg in messages)
            requestMessages.Add(new { role = msg.Role, content = msg.Content });

        var body = new { model = model, messages = requestMessages, max_tokens = 4000, temperature = 0.7 };
        var json = JsonConvert.SerializeObject(body);

        foreach (var endpoint in endpoints)
        {
            try
            {
                var content = new StringContent(json, Encoding.UTF8, "application/json");
                var response = await _httpClient.PostAsync(endpoint, content, ct);
                var responseText = await response.Content.ReadAsStringAsync(ct);

                if (response.IsSuccessStatusCode)
                {
                    var result = JObject.Parse(responseText);
                    var answer = result["choices"]?[0]?["message"]?["content"]?.ToString();
                    if (!string.IsNullOrEmpty(answer))
                        return answer;
                }
                
                System.Diagnostics.Debug.WriteLine($"Endpoint {endpoint} failed: {response.StatusCode}");
            }
            catch (Exception ex)
            {
                System.Diagnostics.Debug.WriteLine($"Endpoint {endpoint} error: {ex.Message}");
            }
        }

        return "âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Azure AI\n\nğŸ’¡ Ø¬Ø±Ø¨:\n1. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ AZURE_AI_KEY ÙÙŠ Environment Variables\n2. Ø£Ùˆ ÙØ¹Ù‘Ù„ Llama Ø§Ù„Ù…Ø­Ù„ÙŠ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ù„Ø®ØµÙˆØµÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©";
    }

    private async Task<string> ChatWithLlamaAsync(List<ChatMessage> messages, CancellationToken ct)
    {
        try
        {
            var requestMessages = new List<object> { new { role = "system", content = _settings.SystemPrompt } };
            foreach (var msg in messages)
                requestMessages.Add(new { role = msg.Role, content = msg.Content });

            var body = new { 
                model = "llama-405b", 
                messages = requestMessages, 
                max_tokens = 4000, 
                temperature = 0.7,
                stream = false
            };
            
            var json = JsonConvert.SerializeObject(body);
            var content = new StringContent(json, Encoding.UTF8, "application/json");
            
            var response = await _httpClient.PostAsync($"{_settings.LlamaEndpoint}/v1/chat/completions", content, ct);
            var responseText = await response.Content.ReadAsStringAsync(ct);

            if (response.IsSuccessStatusCode)
            {
                var result = JObject.Parse(responseText);
                var answer = result["choices"]?[0]?["message"]?["content"]?.ToString();
                if (!string.IsNullOrEmpty(answer))
                    return $"ğŸ¦™ {answer}";
            }
            
            return $"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Llama Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¹Ù„Ù‰ {_settings.LlamaEndpoint}";
        }
        catch (Exception ex)
        {
            return $"âŒ Ø®Ø·Ø£ Llama: {ex.Message}";
        }
    }
}
