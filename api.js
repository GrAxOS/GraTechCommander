// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸš€ GraTech Commander - AI API Integration (PRODUCTION)
// By Suliman Nazal Alshammari | @Grar00t | @GrAxOS
// "Building with HONESTY - Not Vaporware!" 
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// ğŸ”’ API Configuration - Uses Azure Functions Proxy
const API_CONFIG = {
  // REAL Azure Function Proxy (your academic key is safe on server)
  proxyUrl: 'https://gratech-ai-proxy.azurewebsites.net/api/chat',
  
  apiVersion: '2024-08-01-preview',
  
  // Available Models
  models: {
    'gpt-4o': { name: 'GPT-4o', icon: 'ğŸš€', description: 'Ø§Ù„Ø£Ø³Ø±Ø¹ ÙˆØ§Ù„Ø£Ø°ÙƒÙ‰' },
    'gpt-4': { name: 'GPT-4', icon: 'ğŸ’¬', description: 'Ù…ØªÙˆØ§Ø²Ù† ÙˆÙ‚ÙˆÙŠ' },
    'gpt-35-turbo': { name: 'GPT-3.5', icon: 'âš¡', description: 'Ø§Ù‚ØªØµØ§Ø¯ÙŠ ÙˆØ³Ø±ÙŠØ¹' }
  }
};

// ğŸ¯ Rate Limiting for Free Demo
const RATE_LIMIT = {
  maxRequestsPerHour: 30,
  requests: [],
  
  canMakeRequest() {
    const now = Date.now();
    const hourAgo = now - (60 * 60 * 1000);
    this.requests = this.requests.filter(t => t > hourAgo);
    return this.requests.length < this.maxRequestsPerHour;
  },
  
  recordRequest() {
    this.requests.push(Date.now());
    localStorage.setItem('gratech_requests', JSON.stringify(this.requests));
  },
  
  getRemainingRequests() {
    const now = Date.now();
    const hourAgo = now - (60 * 60 * 1000);
    this.requests = this.requests.filter(t => t > hourAgo);
    return this.maxRequestsPerHour - this.requests.length;
  },
  
  init() {
    const saved = localStorage.getItem('gratech_requests');
    if (saved) {
      try {
        this.requests = JSON.parse(saved);
      } catch(e) {
        this.requests = [];
      }
    }
  }
};

// ğŸ¤– AI Chat Function - REAL API CALL
async function sendToAI(message, model = 'gpt-4o') {
  // Check if user has custom key
  const customKey = localStorage.getItem('gratech_api_key');
  const customEndpoint = localStorage.getItem('gratech_endpoint');
  
  if (customKey && customEndpoint) {
    return await sendWithCustomKey(message, customKey, customEndpoint, model);
  }
  
  // Demo mode - rate limited
  if (!RATE_LIMIT.canMakeRequest()) {
    return {
      success: false,
      error: `âš ï¸ ÙˆØµÙ„Øª Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ (${RATE_LIMIT.maxRequestsPerHour} Ø±Ø³Ø§Ù„Ø©/Ø³Ø§Ø¹Ø©)\n\nğŸ’¡ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ØºÙŠØ± Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯:\nâ€¢ Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­Ùƒ Ø§Ù„Ø®Ø§Øµ ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\nâ€¢ Ø£Ùˆ Ø§Ù†ØªØ¸Ø± Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©`
    };
  }
  
  try {
    console.log('ğŸš€ Sending to GraTech AI Proxy:', model);
    
    const response = await fetch(API_CONFIG.proxyUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        message: message,
        model: model,
        sessionId: getSessionId()
      })
    });

    const data = await response.json();
    
    if (response.ok && data.message) {
      RATE_LIMIT.recordRequest();
      return {
        success: true,
        message: data.message,
        model: API_CONFIG.models[model]?.name || model,
        remaining: RATE_LIMIT.getRemainingRequests()
      };
    } else {
      console.error('API Error:', data);
      return {
        success: false,
        error: data.error || 'ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ'
      };
    }
  } catch (error) {
    console.error('Network Error:', error);
    return {
      success: false,
      error: `âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ©: ${error.message}\n\nğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† Ø§ØªØµØ§Ù„Ùƒ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª`
    };
  }
}

// ğŸ”„ Use Custom API Key (BYOK) - Unlimited
async function sendWithCustomKey(message, apiKey, endpoint, model = 'gpt-4') {
  // Clean endpoint
  endpoint = endpoint.replace(/\/$/, '');
  
  const url = `${endpoint}/openai/deployments/${model}/chat/completions?api-version=2024-08-01-preview`;
  
  const body = {
    messages: [
      { role: 'system', content: 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø©. ØµÙÙ†Ø¹Øª Ø¨ÙˆØ§Ø³Ø·Ø© GraTech ğŸ‡¸ğŸ‡¦' },
      { role: 'user', content: message }
    ],
    max_tokens: 4000,
    temperature: 0.7
  };

  try {
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': apiKey
      },
      body: JSON.stringify(body)
    });

    const data = await response.json();
    
    if (response.ok && data.choices) {
      return { 
        success: true, 
        message: data.choices[0].message.content,
        model: model,
        unlimited: true
      };
    } else {
      return { 
        success: false, 
        error: `âŒ ${data.error?.message || 'Ø®Ø·Ø£ ÙÙŠ API'}\n\nğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…ÙØªØ§Ø­ ÙˆØ§Ù„Ù€ Endpoint`
      };
    }
  } catch (error) {
    return { 
      success: false, 
      error: `âŒ ${error.message}` 
    };
  }
}

// ğŸ†” Session ID
function getSessionId() {
  let sid = localStorage.getItem('gratech_session');
  if (!sid) {
    sid = 'gt_' + Math.random().toString(36).substr(2, 9) + Date.now().toString(36);
    localStorage.setItem('gratech_session', sid);
  }
  return sid;
}

// ğŸ“Š Usage Stats
function getUsageStats() {
  return {
    remaining: RATE_LIMIT.getRemainingRequests(),
    max: RATE_LIMIT.maxRequestsPerHour,
    hasCustomKey: !!(localStorage.getItem('gratech_api_key'))
  };
}

// Initialize
RATE_LIMIT.init();

// Export
window.GraTechAI = {
  send: sendToAI,
  sendCustom: sendWithCustomKey,
  getStats: getUsageStats,
  models: API_CONFIG.models
};

console.log('ğŸš€ GraTech AI Ready! | Proxy: gratech-ai-proxy.azurewebsites.net');
console.log('ğŸ“Š Remaining:', RATE_LIMIT.getRemainingRequests(), '/', RATE_LIMIT.maxRequestsPerHour);
